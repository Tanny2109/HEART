# Hugging Face Inference Script Usage

## Overview
This script performs inference using your fine-tuned model weights to generate conversations based on the CSV data. It replaces AutoGen with direct Hugging Face transformers inference.

## Features
- Uses your model weights from `~/HEART/models/SFT/complete_models/model_name/`
- Processes CSV data from `data/insta/type7_version3_output.csv`
- Generates conversations using character information from the CSV
- Pure Hugging Face transformers implementation (no AutoGen)
- GPU support with automatic device detection
- Progress tracking and error handling

## Usage

### Basic Usage
```bash
cd ~/HEART
python scripts/hf_inference.py
```

### With Custom Parameters
```bash
python scripts/hf_inference.py \
    --model_path ~/HEART/models/SFT/complete_models/empathy_15 \
    --csv_path data/insta/type7_version3_output.csv \
    --output_path my_results.csv \
    --sample_size 100 \
    --device cuda:0
```

### Parameters
- `--model_path`: Path to your model directory (default: `~/HEART/models/SFT/complete_models/empathy_15`)
- `--csv_path`: Path to input CSV file (default: `data/insta/type7_version3_output.csv`)
- `--output_path`: Path to output CSV file (default: auto-generated with timestamp)
- `--sample_size`: Number of rows to process for testing (optional, processes all rows if not specified)
- `--device`: Device to use (`auto`, `cuda:0`, `cpu`, etc., default: `auto`)

### Available Models
You can use any of these models:
- `~/HEART/models/SFT/complete_models/empathy_15/`
- `~/HEART/models/SFT/complete_models/empathy_10/`
- `~/HEART/models/SFT/complete_models/empathy_05/`

## Testing
Run a quick test with 2 samples:
```bash
python scripts/test_hf_inference.py
```

## Output
The script generates a CSV file with the following columns:
- `original_index`: Original row index from input CSV
- `csv1_input`: Original input text
- `agent2_output_json`: Character information JSON
- `agent3_output_converted`: Original conversation data
- `hf_generated_conversation`: New conversation generated by your model
- `model_used`: Model identifier
- `timestamp`: Processing timestamp
- `error`: Error message if any

## Examples

### Process full dataset with empathy_15 model:
```bash
python scripts/hf_inference.py --model_path ~/HEART/models/SFT/complete_models/empathy_15
```

### Process 50 samples for testing:
```bash
python scripts/hf_inference.py --sample_size 50 --output_path test_50_samples.csv
```

### Use specific GPU:
```bash
python scripts/hf_inference.py --device cuda:1
```

## Requirements
- PyTorch with CUDA support
- Transformers library
- pandas, tqdm, numpy
- Sufficient GPU memory (model is loaded in float16 for efficiency)

## Performance Notes
- The script uses float16 precision for memory efficiency
- Automatic device mapping for multi-GPU systems
- Progress bar shows processing status
- Error handling continues processing even if some rows fail 