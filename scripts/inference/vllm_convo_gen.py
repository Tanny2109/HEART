import argparse
from autogen import AssistantAgent, UserProxyAgent, config_list_from_json
import pandas as pd
import json
import ast
import os
from tqdm import tqdm
from collections import defaultdict

# For parallelization
from joblib import Parallel, delayed
from datetime import datetime

# config_list = [
#     {
#         "model": "llama3.1",  # The model name you pulled
#         "base_url": "http://localhost:11434/v1",  # Note the /v1 suffix
#         "api_key": "ollama",  # Required but arbitrary value
#         "temperature": 1.0,
#         "max_tokens": 512,
#     }
# ]
llm_config = {
    "config_list": [
        {
            "model": "meta-llama/Llama-3.1-8B",  # The model name you pulled
            "base_url": "http://localhost:11434/v1",  # Note the /v1 suffix
            "api_key": "ollama",  # Required but arbitrary value
            # "temperature": 0.7,
            "max_tokens": 512,
        }
    ],
    "temperature": 0.7 
    # repeat penalty 0.97 to make it not repeat sentences...
}

def deserialize_chat_messages(chat_messages):
    """
    Deserializes the chat messages from a defaultdict and converts it into a JSON-serializable format.
    """
    serialized_messages = []
    
    for agent, messages in chat_messages.items():
        agent_name = str(agent)  # or agent.name, if that attribute exists
        for message in messages:
            serialized_message = {
                "agent": agent_name,
                "content": message.get("content"),
                "role": message.get("role"),
                "name": message.get("name")
            }
            serialized_messages.append(serialized_message)
    
    return serialized_messages

def process_single_row(row):
    """
    This function takes a row of a DataFrame, runs the Bullying Simulation logic,
    and returns the JSON-serialized conversation or an error message.
    """
    try:
        conversation_attr_dict = json.loads(row['agent2_output_json'])
        # convert all the keys to lowercase to avoid case sensitivity issues
        conversation_attr_dict = {k.lower(): v for k, v in conversation_attr_dict.items()}
        harasser_name = conversation_attr_dict['harasser']
        victim_name = conversation_attr_dict['victim']
        harasser_role = conversation_attr_dict['harassment goal']

        # Get the synthetic conversation generated by pinxian
        # conversation = ast.literal_eval(row['agent3_output_filtered'])
        conversation = ast.literal_eval(row['agent3_output_converted']) # pinxian is not filtering the data anymore
        # Get the initial message
        harasser_initial_starter_message = conversation[0]['message']

        # Remove the harasser's name from the initial message if present
        if harasser_name in harasser_initial_starter_message:
            harasser_initial_starter_message = harasser_initial_starter_message.replace(harasser_name, "")

        # without memory
        h_agent = AssistantAgent(
            name=harasser_name,
            system_message=(
                f"You are an assistant. Your name is {harasser_name} "
                f"and your role is {harasser_role}:"
            ),
            # llm_config={"config_list": config_list},
            llm_config=llm_config,
        )

        v_agent = AssistantAgent(
            name=victim_name,
            system_message=(
                f"You are an assistant. Your name is {victim_name} "
                "and your role is victim:"
            ),
            # llm_config={"config_list": config_list},
            llm_config=llm_config,
        )

        # Start the conversation
        h_agent.initiate_chat(
            v_agent,
            message=harasser_initial_starter_message,
            max_turns=10  # Limit conversation turns
        )

        # Obtain and serialize the chat messages
        chat_messages = h_agent.chat_messages
        serialized_chat_messages = deserialize_chat_messages(chat_messages)

        # Return the result to store
        return json.dumps(serialized_chat_messages, indent=4)

    except Exception as e:
        return f'ERROR: {e}'

def main():
    parser = argparse.ArgumentParser(description="Run Bullying Simulation with Jailbreaking")
    parser.add_argument("--input_csv", required=True, help="Path to the input CSV file")
    parser.add_argument("--output_dir", required=True, help="Directory to save the output CSV file")
    args = parser.parse_args()

    input_csv = args.input_csv
    output_dir = args.output_dir

    # Load the CSV file into a pandas DataFrame
    df = pd.read_csv(input_csv)
    df = df[:10]
    print('Loaded dataframes successfully')

    print('Running Bullying Simulation with', input_csv)

    # Use joblib to parallelize over df rows
    results = Parallel(n_jobs=4)(
        delayed(process_single_row)(row) 
        for _, row in tqdm(df.iterrows(), 
                           desc='Running Bullying Simulation over the dataset', 
                           total=len(df))
    )
    # results without parallelization for debugging
    # results = []
    # for index, row in tqdm(df.iterrows(), desc='Running Bullying Simulation over the dataset', total=len(df)):
    #     result = process_single_row(row)
    #     results.append(result)

    # Store the results in a new column
    df['bully_chat_history'] = results

    # Save the updated DataFrame to a new CSV file
    current_date = datetime.now().strftime("%Y%m%d")
    output_csv_path = os.path.join(output_dir, f"vllm_jailbreak_meta-llama-3.1-8B_{current_date}_{os.path.basename(input_csv)}")
    print('Simulation Completed, Now saving the file to', output_csv_path)
    os.makedirs(output_dir, exist_ok=True)
    df.to_csv(output_csv_path, index=False)

if __name__ == "__main__":
    main()
